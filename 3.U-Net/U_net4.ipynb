{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "import numpy as np\n",
    "from torchvision.models import resnet101\n",
    "import torch.nn as nn\n",
    "import os\n",
    "import cv2\n",
    "import random\n",
    "import torch.utils.model_zoo as model_zoo\n",
    "from copy import deepcopy\n",
    "\n",
    "from matplotlib import cm\n",
    "import scipy.misc as misc\n",
    "import matplotlib\n",
    "import imageio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "\n",
    "class IntermediateLayerGetter(nn.ModuleDict):\n",
    "    \"\"\"\n",
    "    Module wrapper that returns intermediate layers from a model\n",
    "    It has a strong assumption that the modules have been registered\n",
    "    into the model in the same order as they are used.\n",
    "    This means that one should **not** reuse the same nn.Module\n",
    "    twice in the forward if you want this to work.\n",
    "    Additionally, it is only able to query submodules that are directly\n",
    "    assigned to the model. So if `model` is passed, `model.feature1` can\n",
    "    be returned, but not `model.feature1.layer2`.\n",
    "    Arguments:\n",
    "        model (nn.Module): model on which we will extract the features\n",
    "        return_layers (Dict[name, new_name]): a dict containing the names\n",
    "            of the modules for which the activations will be returned as\n",
    "            the key of the dict, and the value of the dict is the name\n",
    "            of the returned activation (which the user can specify).\n",
    "    Examples::\n",
    "        >>> m = torchvision.models.resnet18(pretrained=True)\n",
    "        >>> # extract layer1 and layer3, giving as names `feat1` and feat2`\n",
    "        >>> new_m = torchvision.models._utils.IntermediateLayerGetter(m,\n",
    "        >>>     {'layer1': 'feat1', 'layer3': 'feat2'})\n",
    "        >>> out = new_m(torch.rand(1, 3, 224, 224))\n",
    "        >>> print([(k, v.shape) for k, v in out.items()])\n",
    "        >>>     [('feat1', torch.Size([1, 64, 56, 56])),\n",
    "        >>>      ('feat2', torch.Size([1, 256, 14, 14]))]\n",
    "    \"\"\"\n",
    "    def __init__(self, model, return_layers):\n",
    "        if not set(return_layers).issubset([name for name, _ in model.named_children()]):\n",
    "            raise ValueError(\"return_layers are not present in model\")\n",
    "\n",
    "        orig_return_layers = return_layers\n",
    "        return_layers = {k: v for k, v in return_layers.items()}\n",
    "        layers = OrderedDict()\n",
    "        for name, module in model.named_children():\n",
    "            layers[name] = module\n",
    "            if name in return_layers:\n",
    "                del return_layers[name]\n",
    "            if not return_layers:\n",
    "                break\n",
    "\n",
    "        super(IntermediateLayerGetter, self).__init__(layers)\n",
    "        self.return_layers = orig_return_layers\n",
    "        #self.softmax = nn.Softmax(dim=2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = OrderedDict()\n",
    "        for name, module in self.named_children():\n",
    "            x = module(x)\n",
    "            if name in self.return_layers:\n",
    "                out_name = self.return_layers[name]\n",
    "                out[out_name] = x#self.softmax(x)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class DoubleConv(nn.Module):#为U_Net模型中的双卷积结构\n",
    "    def __init__(self, in_ch, out_ch):\n",
    "        super(DoubleConv, self).__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(in_ch, out_ch, 3, padding=1),#此处包含padding，为了使输出图像与原图像大小相同\n",
    "            nn.BatchNorm2d(out_ch),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_ch, out_ch, 3, padding=1),\n",
    "            nn.BatchNorm2d(out_ch),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.conv(input)\n",
    "\n",
    "\n",
    "class Unet(nn.Module):\n",
    "    def __init__(self,in_ch,out_ch):\n",
    "        super(Unet, self).__init__()\n",
    "\n",
    "        self.conv1 = DoubleConv(in_ch, 64)\n",
    "        self.pool1 = nn.MaxPool2d(2)\n",
    "        self.conv2 = DoubleConv(64, 128)\n",
    "        self.pool2 = nn.MaxPool2d(2)\n",
    "        self.conv3 = DoubleConv(128, 256)\n",
    "        self.pool3 = nn.MaxPool2d(2)\n",
    "        self.conv4 = DoubleConv(256, 512)\n",
    "        self.pool4 = nn.MaxPool2d(2)\n",
    "        self.conv5 = DoubleConv(512, 1024)\n",
    "        self.up6 = nn.ConvTranspose2d(1024, 512, 2, stride=2)\n",
    "        self.conv6 = DoubleConv(1024, 512)\n",
    "        self.up7 = nn.ConvTranspose2d(512, 256, 2, stride=2)\n",
    "        self.conv7 = DoubleConv(512, 256)\n",
    "        self.up8 = nn.ConvTranspose2d(256, 128, 2, stride=2)\n",
    "        self.conv8 = DoubleConv(256, 128)\n",
    "        self.up9 = nn.ConvTranspose2d(128, 64, 2, stride=2)\n",
    "        self.conv9 = DoubleConv(128, 64)\n",
    "        self.conv10 = nn.Conv2d(64,out_ch, 1)\n",
    "\n",
    "    def forward(self,x):\n",
    "        c1=self.conv1(x)\n",
    "        p1=self.pool1(c1)\n",
    "        c2=self.conv2(p1)\n",
    "        p2=self.pool2(c2)\n",
    "        c3=self.conv3(p2)\n",
    "        p3=self.pool3(c3)\n",
    "        c4=self.conv4(p3)\n",
    "        p4=self.pool4(c4)\n",
    "        c5=self.conv5(p4)\n",
    "        up_6= self.up6(c5)\n",
    "        merge6 = torch.cat([up_6, c4], dim=1)\n",
    "        c6=self.conv6(merge6)\n",
    "        up_7=self.up7(c6)\n",
    "        merge7 = torch.cat([up_7, c3], dim=1)\n",
    "        c7=self.conv7(merge7)\n",
    "        up_8=self.up8(c7)\n",
    "        merge8 = torch.cat([up_8, c2], dim=1)\n",
    "        c8=self.conv8(merge8)\n",
    "        up_9=self.up9(c8)\n",
    "        merge9=torch.cat([up_9,c1],dim=1)\n",
    "        c9=self.conv9(merge9)\n",
    "        c10=self.conv10(c9)\n",
    "        out = nn.Sigmoid()(c10)\n",
    "        return out\n",
    "\n",
    "model=Unet(1,1).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#criterion = nn.CrossEntropyLoss()\n",
    "# model.load_state_dict(torch.load(\"deep3_(4_8).pkl\"))\n",
    "#criterion = nn.BCELoss()\n",
    "learning_rate=0.0001\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n",
      "1400\n",
      "1500\n",
      "1600\n",
      "1700\n",
      "1800\n",
      "1900\n",
      "2000\n",
      "2100\n",
      "2200\n"
     ]
    }
   ],
   "source": [
    "import csv,os\n",
    "def get_csv():\n",
    "    class_path  =  '...\\\\Data\\\\img\\\\'\n",
    "    class_path3  = '...\\\\2.deeplab\\\\gen_t3\\\\'\n",
    "    blanket=set()\n",
    "    blanket2={}\n",
    "\n",
    "    #############case3\n",
    "    blanket.add(6)\n",
    "    blanket.add(21)\n",
    "    blanket.add(27)\n",
    "#################case1\n",
    "#     blanket.add(8)\n",
    "#     blanket.add(9)\n",
    "#     blanket.add(2)\n",
    "###############case2\n",
    "#     blanket.add(5)\n",
    "#     blanket.add(15)\n",
    "#     blanket.add(18)\n",
    "###############case4\n",
    "#     blanket.add(7)\n",
    "#     blanket.add(29)\n",
    "#     blanket.add(34)\n",
    "\n",
    "\n",
    "#     for img_name in os.listdir(class_path):\n",
    "#         info=str.split(img_name,\"_\")\n",
    "#         blanket2[info[1]]=info[0]\n",
    "#     for key in blanket2:\n",
    "#         print(key+':'+blanket2[key])\n",
    "\n",
    "#     return\n",
    "    with open('case3_before_o.csv','w',newline='')as f:\n",
    "        f_csv = csv.writer(f)\n",
    "        i=0\n",
    "        for img_name in os.listdir(class_path3):\n",
    "            if img_name[0]!='_':\n",
    "                continue\n",
    "            info=str.split(img_name[1:],\"_\")\n",
    "#             print(info)\n",
    "            info3=info[0]\n",
    "#             print(info3) #path\n",
    "            info2=str.split(info[1],\".\")\n",
    "            info2=info2[0]+\".bmp\"\n",
    "#             print(info2) #file\n",
    "            img_path2= class_path + info3+'\\\\'+info2\n",
    "            img_path = class_path3+img_name\n",
    "            temp=[2]\n",
    "            temp.append(img_path2)\n",
    "            img_name2=str.split(img_name[1:],\".\")\n",
    "            img_name2=img_name2[0]+'.bmp'\n",
    "            temp.append(img_name2)\n",
    "            temp.append(img_path)\n",
    "            temp.append(\"\")\n",
    "            f_csv.writerow(temp)\n",
    "#             break\n",
    "            i=i+1\n",
    "            if i%100==0:\n",
    "                print(i)\n",
    "#             break\n",
    "\n",
    "get_csv()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#keep the X contain the original image \n",
    "def load_data(label_path):\n",
    "    labels_list=open(label_path, 'r')\n",
    "    X,Y,Z,W=[],[],[],[]\n",
    "    i=1\n",
    "    c=0\n",
    "    d=0\n",
    "    for line in labels_list:\n",
    "        info=str.split(line,\",\") \n",
    "        if i==1:\n",
    "            print(info[1])\n",
    "            print(info[3])\n",
    "        X.append(np.expand_dims(imageio.imread(info[1]),axis=2))#orginal image\n",
    "#         a=imageio.imread(info[3])\n",
    "        W.append(np.expand_dims(imageio.imread(info[3]),axis=2))\n",
    "#         b=np.max(a)\n",
    "#         if b!=0:\n",
    "#             b=1\n",
    "#         if b:\n",
    "#             d+=1\n",
    "#         else:\n",
    "#             c+=1\n",
    "        Y.append(2)\n",
    "        Z.append(str(info[2]))\n",
    "        #break\n",
    "#         print(X[0].shape)\n",
    "#         print(X[0].shape)\n",
    "        i+=1\n",
    "        if i%100==0:\n",
    "            print(i)\n",
    "#     print(c,d)\n",
    "    return list(zip(X,Y,Z,W))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F:\\Ruiveen2\\Data\\img\\10072\\1.bmp\n",
      "F:\\tq\\2020\\5\\23\\王铁桥-毕业论文-程序\\2.deeplab\\gen_t3\\_10072_1.bmp\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n",
      "1400\n",
      "1500\n",
      "1600\n",
      "1700\n",
      "1800\n",
      "1900\n",
      "2000\n",
      "2100\n",
      "2200\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# data=load_data(\"/media/students/000FF23E00059C2D/tq/2019/8/20/gen_test2.csv\")\n",
    "# data=load_data2(\"case4_before_o.csv\")\n",
    "# data=load_data3(\"my_test2.csv\")\n",
    "# data=load_data(\"unet_train2.csv\")\n",
    "data=load_data(\"case3_before_o.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model.load_state_dict(torch.load(\"deep1_o.pkl\"))\n",
    "mmpp=87685435454 # 1194110\n",
    "model.load_state_dict(torch.load(\"unet3_o.pkl\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# #prepare data W{}\n",
    "# with torch.no_grad():\n",
    "#     batch_size=2\n",
    "#     num_epochs=1\n",
    "#     for epoch in range(num_epochs):\n",
    "#         random.shuffle(data)\n",
    "#         X, Y,_,W= zip(*data)\n",
    "#         X=np.array(X).transpose((0,3,1,2))\n",
    "#         W=np.array(W).transpose((0,3,1,2))\n",
    "#         Y=np.array(Y)\n",
    "#         for i in range(0,X.shape[0],batch_size):\n",
    "#             if i+batch_size>=X.shape[0]: break\n",
    "#             batch=torch.from_numpy(X[i:i+batch_size]).cuda().float()\n",
    "#             outputs=model(batch)\n",
    "#             outputs2=outputs.cpu().detach()\n",
    "#             if i%100==0:\n",
    "#                 print(i)\n",
    "#             for j in range(batch_size):\n",
    "#                 if Y[i+j]==1:\n",
    "#                     W[i+j]=outputs2[j]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/100], step[0/1117],Loss: 0.00087432190775871277\n",
      "0.0008743219077587128\n"
     ]
    }
   ],
   "source": [
    "import random #训练\n",
    "batch_size=2\n",
    "num_epochs=100\n",
    "criterion = nn.CrossEntropyLoss()#torch.tensor([1,512]).float().cuda())\n",
    "criterion2 = nn.BCELoss()\n",
    "\n",
    "m=nn.Softmax(dim=1)\n",
    "for epoch in range(num_epochs):\n",
    "    count=0\n",
    "    random.shuffle(data)\n",
    "    X, Y,_,W= zip(*data)\n",
    "    X=np.array(X).transpose((0,3,1,2))\n",
    "    W=np.array(W).transpose((0,3,1,2))\n",
    "    #print(W.shape)\n",
    "    mm=0\n",
    "    for i in range(0,X.shape[0],batch_size):\n",
    "        if i+batch_size>=X.shape[0]: break\n",
    "        batch=torch.from_numpy(X[i:i+batch_size]).cuda().float()\n",
    "        outputs=model(batch)\n",
    "#         outputs2=outputs.cpu().detach()\n",
    "        outputs=outputs.squeeze()\n",
    "        labels=torch.from_numpy(W[i:i+batch_size]).cuda().float()\n",
    "#         for j in range(batch_size):\n",
    "#             if Y[i+j]==1:\n",
    "#                 W[i+j]=outputs2[j]\n",
    "#         print(labels.shape)\n",
    "        labels=torch.clamp(labels,0,1)\n",
    "        labels=labels.view(labels.shape[0],labels.shape[2],labels.shape[3])\n",
    "        loss = criterion2(outputs, labels)\n",
    "        o_,pred=torch.max(outputs,1)\n",
    "        mm+=loss.item()\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if count%100==0:\n",
    "            print('Epoch [{}/{}], step[{}/{}],Loss: {:.20f}'.format(epoch + 1, num_epochs, count,X.shape[0]//batch_size,loss.item()))\n",
    "            print(mm)\n",
    "        count += 1\n",
    "    if mm<mmpp:\n",
    "        mmpp=mm\n",
    "        torch.save(model.state_dict(),\"unet5_o.pkl\")\n",
    "#         learning_rate=min(0.02,learning_rate+0.0001)\n",
    "#         optimizer = torch.optim.Ada m(model.parameters(), lr=learning_rate)\n",
    "    else:\n",
    "        torch.save(model.state_dict(),\"unet5_o.pkl\")\n",
    "#         learning_rate=0.0001\n",
    "#         optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    print(mm)\n",
    "    print(mmpp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
